{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0aa4d356-625b-4749-98c3-c2ad4a600e58",
   "metadata": {},
   "source": [
    "# import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85017974-cc86-4227-9fe9-59881852ce88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import csv\n",
    "import torch\n",
    "import shutil\n",
    "import pandas\n",
    "import pickle\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "from thop import profile\n",
    "from datetime import datetime\n",
    "from btlbo_unet.loss import *\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import DataLoader\n",
    "from util.create_dir import create_dirs\n",
    "from torchvision.utils import save_image\n",
    "from btlbo_unet.btlbo import BTLBOUNet22\n",
    "from util.get_optimizer import get_optimizer\n",
    "from loss.FocalLoss import FocalLossForSigmoid\n",
    "from metrics.average_meter import AverageMeter\n",
    "from dataset.util.get_datasets import get_datasets\n",
    "from torch.nn.utils.clip_grad import clip_grad_norm_\n",
    "from metrics.calculate_metrics import calculate_metrics\n",
    "\n",
    "seed = 7546\n",
    "np.random.seed(seed)\n",
    "\n",
    "optimizer_name = 'Adam' #'Lookahead(Adam)'\n",
    "learning_rate = 0.001\n",
    "l2_weight_decay = 0\n",
    "epochs = 80\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e51f889-7a38-40ad-ac4e-3cb5186ca36a",
   "metadata": {},
   "source": [
    "## Dataset Preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebb7aaf-7320-4f92-b191-019abaf20c70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_name = 'CHASEDB'\n",
    "                                                                                                                            \n",
    "train_set_root = os.path.join(os.path.abspath('.'), 'dataset', 'trainset', dataset_name)\n",
    "valid_set_root = os.path.join(os.path.abspath('.'), 'dataset', 'testset', dataset_name)\n",
    "batch_size = 2\n",
    "\n",
    "train_set, num_return = get_datasets(dataset_name, train_set_root, True)\n",
    "valid_set, _ = get_datasets(dataset_name, valid_set_root, False)\n",
    "train_loader = DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True, num_workers=3)\n",
    "valid_loader = DataLoader(dataset=valid_set, batch_size=1, shuffle=False, num_workers=1)\n",
    "print(len(train_set), len(valid_set))\n",
    "\n",
    "metrics_name = ['flops', 'param', 'accuracy', 'recall', 'specificity', 'precision', 'f1_score', 'dice', 'auroc', 'iou']        \n",
    "metrics1 = {'whole_best_f1_score': 0, 'train_best_f1_score': 0}\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "LOSS_Functions = [FocalLossForSigmoid(reduction='mean').to(device), DiceBCELoss()]  #, FocalTverskyLoss(), DiceLoss()\n",
    "                 \n",
    "def todec(b):\n",
    "    #print(b)\n",
    "    return int(''.join(map(lambda x: str(int(x)), b)), 2)\n",
    "\n",
    "\n",
    "create_dirs(\"results\")\n",
    "file_name = 'results/'+dataset_name+'.csv'\n",
    "print(file_name)\n",
    "\n",
    "if not os.path.exists(file_name):\n",
    "    print(\"writing new\")\n",
    "    with open(file_name,'a') as fp:\n",
    "        wr = csv.writer(fp, dialect='excel')\n",
    "        wr.writerow(['generation', 'Index', 'epoch', 'acc', 'recall', 'spe', 'pre', 'f1_score', 'dice', 'auroc', \\\n",
    "                     'mins', 'stime', 'etime', 'loss', 'Particle', 'flops', 'param'])\n",
    "\n",
    "mpath = 'results/'+dataset_name+'_model_02.pth'   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d577bb71-cd33-420f-aebd-3a1c84a5f12c",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bed6a5-7301-4946-b8dd-7302af20a462",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def runModel(g, index, particle, rerun=False):\n",
    "    ptcl = ' '.join(map(str, particle))\n",
    "    print(particle)\n",
    "    if not rerun:\n",
    "        f = pandas.read_csv(file_name)\n",
    "        if ptcl in f['Particle'].values:\n",
    "            print(\"already found\")\n",
    "            f1s = float(np.max(f[f['Particle'] == ptcl]['dice']))\n",
    "            return f1s, None\n",
    "    model_name = 'BTUNet'\n",
    "    start = time.time()\n",
    "    model = BTLBOUNet22(particle)\n",
    "    model.to(device)\n",
    "    lrn = particle[140]\n",
    "    print(lrn)\n",
    "    loss_func = LOSS_Functions[lrn]\n",
    "    print(loss_func)\n",
    "    optimizer = get_optimizer(optimizer_name, filter(lambda p: p.requires_grad, model.parameters()), learning_rate, l2_weight_decay)\n",
    "    best_dice = 0\n",
    "    flag = 0\n",
    "    count = 0\n",
    "    valid_epoch = 50\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    \n",
    "    metrics = {}\n",
    "    for metric_name in metrics_name:\n",
    "        if metric_name == 'flops' or metric_name == 'param':\n",
    "            metrics.update({metric_name: 100})\n",
    "        else:\n",
    "            metrics.update({metric_name: 0})\n",
    "\n",
    "    \n",
    "    ##Training\n",
    "    for i in range(150):\n",
    "        print(\"epoch {}\".format(i))\n",
    "        train_tqdm_batch = tqdm(iterable=train_loader, total=numpy.ceil(len(train_set) / batch_size))\n",
    "        c = 0\n",
    "        \n",
    "        epoch_acc1 = AverageMeter()\n",
    "        epoch_recall1 = AverageMeter()\n",
    "        epoch_precision1 = AverageMeter()\n",
    "        epoch_specificity1 = AverageMeter()\n",
    "        epoch_f1_score1 = AverageMeter()\n",
    "        epoch_dice1 = AverageMeter()\n",
    "        epoch_iou1 = AverageMeter()\n",
    "        epoch_auroc1 = AverageMeter() \n",
    "\n",
    "    \n",
    "        for images, targets in train_tqdm_batch:\n",
    "            optimizer.zero_grad()\n",
    "            images = images.to(device)\n",
    "            targets = targets.to(device)\n",
    "            preds = model(images)\n",
    "            preds1 = preds.clone()\n",
    "            preds1[preds <= 0.5] = 0\n",
    "            preds1[preds > 0.5] = 1\n",
    "            \n",
    "            loss = loss_func(preds, targets)\n",
    "            loss.backward()\n",
    "            clip_grad_norm_(model.parameters(), 0.1)\n",
    "            optimizer.step()\n",
    "            \n",
    "            \n",
    "            (acc, recall, specificity, precision,\n",
    "                         f1_score, dice, iou, auroc) = calculate_metrics(preds=preds1, targets=targets, device=device)\n",
    "            epoch_acc1.update(acc)\n",
    "            epoch_recall1.update(recall)\n",
    "            epoch_precision1.update(precision)\n",
    "            epoch_specificity1.update(specificity)\n",
    "            epoch_f1_score1.update(f1_score)\n",
    "            epoch_dice1.update(dice)\n",
    "            epoch_iou1.update(iou)\n",
    "            epoch_auroc1.update(auroc)\n",
    "        \n",
    "        \n",
    "        train_tqdm_batch.close()\n",
    "        \n",
    "        print('Training  -- acc:{} | recall:{} | spe:{} | pre:{} | f1_score:{} | dice:{} | auroc:{}'\n",
    "                  .format(epoch_acc1.val,\n",
    "                          epoch_recall1.val,\n",
    "                          epoch_specificity1.val,\n",
    "                          epoch_precision1.val,\n",
    "                          epoch_f1_score1.val,\n",
    "                          epoch_dice1.val,\n",
    "                          epoch_auroc1.val))\n",
    "    \n",
    "        if (metrics1['train_best_f1_score'] < epoch_dice1.val):\n",
    "            metrics1['train_best_f1_score'] = epoch_dice1.val\n",
    "            flag1 = i\n",
    "\n",
    "        epoch_acc = AverageMeter()\n",
    "        epoch_recall = AverageMeter()\n",
    "        epoch_precision = AverageMeter()\n",
    "        epoch_specificity = AverageMeter()\n",
    "        epoch_f1_score = AverageMeter()\n",
    "        epoch_dice = AverageMeter()\n",
    "        epoch_iou = AverageMeter()\n",
    "        epoch_auroc = AverageMeter()\n",
    "\n",
    "        \n",
    "        if (i >= valid_epoch):\n",
    "            print(\"validation\")\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                valid_tqdm_batch = tqdm(iterable=valid_loader, total=numpy.ceil(len(valid_set) / 1))\n",
    "                for images, targets in valid_tqdm_batch:\n",
    "                    images = images.to(device)\n",
    "                    targets = targets.to(device)\n",
    "                    preds = model(images)\n",
    "                    preds1 = preds.clone()\n",
    "                    preds1[preds <= 0.5] = 0\n",
    "                    preds1[preds > 0.5] = 1\n",
    "#                     save_image(np.squeeze(images), 'results/'+dataset_name+'/'+str(c1)+'_images.png')\n",
    "#                     save_image(np.squeeze(preds), 'results/'+dataset_name+'/'+str(c1)+'_preds.png')                    \n",
    "#                     save_image(np.squeeze(preds1), 'results/'+dataset_name+'/'++str(c1)+'_preds1.png')\n",
    "\n",
    "                    (acc, recall, specificity, precision,\n",
    "                     f1_score, dice, iou, auroc) = calculate_metrics(preds=preds1, targets=targets, device=device)\n",
    "                    \n",
    "                    epoch_acc.update(acc)\n",
    "                    epoch_recall.update(recall)\n",
    "                    epoch_precision.update(precision)\n",
    "                    epoch_specificity.update(specificity)\n",
    "                    epoch_f1_score.update(f1_score)\n",
    "                    epoch_dice.update(dice)\n",
    "                    epoch_iou.update(iou)\n",
    "                    epoch_auroc.update(auroc)\n",
    "                    \n",
    "   \n",
    "                if i == valid_epoch:\n",
    "                    try:\n",
    "                        flops, param = profile(model=model, inputs=(images,), verbose=False)\n",
    "                        flops = flops / 1e11\n",
    "                        param = param / 1e6\n",
    "                    except:\n",
    "                        flops =0 \n",
    "                        param = 0\n",
    "\n",
    "                print('metr- acc:{} | recall:{} | spe:{} | pre:{} | f1_score:{} | dice:{} | auroc:{}'\n",
    "                      .format(epoch_acc.val,\n",
    "                              epoch_recall.val,\n",
    "                              epoch_specificity.val,\n",
    "                              epoch_precision.val,\n",
    "                              epoch_f1_score.val,\n",
    "                              epoch_dice.val,\n",
    "                              epoch_auroc.val))\n",
    "                \n",
    "                \n",
    "                if epoch_dice.val > best_dice:\n",
    "                    best_dice = epoch_dice.val\n",
    "                    \n",
    "                    if metrics1['whole_best_f1_score'] < epoch_dice.val:\n",
    "                        metrics1['whole_best_f1_score'] = epoch_dice.val\n",
    "                        torch.save(model, mpath)                        \n",
    "\n",
    "                    flag = i\n",
    "                    count = 0\n",
    "                    for key in list(metrics):\n",
    "                        if key == 'flops':\n",
    "                            metrics[key] = flops\n",
    "                        elif key == 'param':\n",
    "                            metrics[key] = param\n",
    "                        elif key == 'accuracy':\n",
    "                            metrics[key] = epoch_acc.val\n",
    "                        elif key == 'recall':\n",
    "                            metrics[key] = epoch_recall.val\n",
    "                        elif key == 'specificity':\n",
    "                            metrics[key] = epoch_specificity.val\n",
    "                        elif key == 'precision':\n",
    "                            metrics[key] = epoch_precision.val\n",
    "                        elif key == 'f1_score':\n",
    "                            metrics[key] = epoch_f1_score.val\n",
    "                        elif key == 'dice':\n",
    "                            metrics[key] = epoch_dice.val\n",
    "                        elif key == 'auroc':\n",
    "                            metrics[key] = epoch_auroc.val\n",
    "                        elif key == 'iou':\n",
    "                            metrics[key] = epoch_iou.val\n",
    "                        else:\n",
    "                            raise NotImplementedError\n",
    "\n",
    "                else:\n",
    "                    if i >= valid_epoch:\n",
    "                        count += 1\n",
    "\n",
    "                end = None\n",
    "                \n",
    "                if i > valid_epoch + 15 and best_dice < 0.50:\n",
    "                    end = True\n",
    "                \n",
    "                if epoch_dice.val < 0.1 and i > 85:\n",
    "                    print(\"closing as f1sore is not increasing\")\n",
    "                    valid_tqdm_batch.close()\n",
    "                    break\n",
    "                    \n",
    "                if (count >= 70) or end:\n",
    "                    valid_tqdm_batch.close()\n",
    "                    #return metrics, True\n",
    "    #             print('current best epoch_{} best_f1_score:'.format(flag), best_f1_score)\n",
    "                valid_tqdm_batch.close()\n",
    "    print('current best epoch_{} best_f1_score:'.format(flag), best_dice)\n",
    "                \n",
    "    # saving\n",
    "    l=[]\n",
    "    end = time.time()\n",
    "    l.extend([g, index, flag, metrics['accuracy'], metrics['recall'], metrics['specificity'], metrics['precision'], \\\n",
    "              metrics['f1_score'], metrics['dice'], metrics['auroc'], int((end-start)/60), \\\n",
    "              datetime.fromtimestamp(start).strftime('%Y-%m-%d %H:%M:%S'),\\\n",
    "              datetime.fromtimestamp(end).strftime('%Y-%m-%d %H:%M:%S'), loss_func, ptcl])\n",
    "    with open(file_name,'a') as fp:\n",
    "        wr = csv.writer(fp, dialect='excel')\n",
    "        wr.writerow(l)\n",
    "\n",
    "    return best_dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc93303f-3cf7-4a17-ae2d-86ce14a2437e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a25818f3-7fd9-4231-9667-0dddcf39480f",
   "metadata": {},
   "source": [
    "## BLTBO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5945fc36-c3b3-443a-b968-342a5d0c8bc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_population = 20\n",
    "pidx = list(range(n_population))\n",
    "m = 141  # columns\n",
    "MAX_GEN = 30\n",
    "\n",
    "# init population and fitness\n",
    "print(\"Initializing new population and fitness\")\n",
    "# population_ = np.random.randint(0,2,(n_population, m))\n",
    "# fitness_ = np.zeros((n_population,), dtype=np.float32)\n",
    "\n",
    "population_ = [[1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0], \n",
    "[0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0], \n",
    "[1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1], \n",
    "[0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0], \n",
    "[1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0], \n",
    "[0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0], \n",
    "[1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1], \n",
    "[1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0], \n",
    "[0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1], \n",
    "[1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1], \n",
    "[1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0], \n",
    "[0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0], \n",
    "[1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0], \n",
    "[1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1], \n",
    "[1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0], \n",
    "[0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0], \n",
    "[1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1], \n",
    "[1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0], \n",
    "[1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0], \n",
    "[1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0]]\n",
    "fitness_ = [0.8104, 0.8084, 0.8066, 0.8060, 0.8060, 0.8058, 0.8055, 0.8055, 0.8053, 0.8052, 0.8052, 0.8049, 0.8048, 0.8045, 0.8041, 0.8039, 0.8037, 0.8034, 0.8034, 0.8033] \n",
    "\n",
    "population_ = np.array(population_)\n",
    "fitness_ = np.array(fitness_)\n",
    "\n",
    "# custom function\n",
    "import math\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "# define vectorized sigmoid\n",
    "sigmoid_v = np.vectorize(sigmoid)    \n",
    "\n",
    "\n",
    "## BTLBO algorithm starts here which runs for MAX_GEN generations\n",
    "for t in range(MAX_GEN):\n",
    "    pu = []\n",
    "    for i in range(n_population):   #Each solution in pop\n",
    "        print(t, i)\n",
    "\n",
    "    ## teaching phase\n",
    "        mean = np.nanmean(population_, axis=0)  # column mean.    \n",
    "        teacher = np.argmax(fitness_)  # select teacher\n",
    "        T_F = np.random.randint(1, 3)  # teaching factor is randomly 1 or 2.\n",
    "        r_i = np.random.rand(m)  # multiplier also random.\n",
    "\n",
    "        new_solution = population_[i] + (r_i * (population_[teacher] - (T_F * mean)))\n",
    "        \n",
    "        \n",
    "        #bounding\n",
    "        new_solution = np.where(sigmoid_v(new_solution) >= np.random.uniform(size=len(new_solution)), 1, 0)\n",
    "\n",
    "\n",
    "        try:\n",
    "            new_fitness = runModel(t, i, new_solution)\n",
    "        #except tf.errors.ResourceExhaustedError as e:\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            new_fitness = 0\n",
    "\n",
    "        if new_fitness > fitness_[i]:   #Greedy selection\n",
    "            population_[i] = new_solution\n",
    "            fitness_[i] = new_fitness\n",
    "\n",
    "\n",
    "    ## learning phase\n",
    "        try:\n",
    "            p = np.random.choice(list(set(pidx[:i] + pidx[(i+1):])-set(pu)))  # pick another random i!=p\n",
    "        except:\n",
    "            p = np.random.choice(pidx[:i] + pidx[(i + 1):], 1)\n",
    "        pu.append(p)\n",
    "        r_i = np.random.rand(m)\n",
    "\n",
    "        if fitness_[i] < fitness_[p]:\n",
    "            new_solution = population_[i] + r_i * (population_[i] - population_[p]).flatten()\n",
    "        else:\n",
    "            new_solution = population_[i] - r_i * (population_[i] - population_[p]).flatten()\n",
    "\n",
    "        #bounding\n",
    "        new_solution = np.where(sigmoid_v(new_solution) >= np.random.uniform(size=len(new_solution)), 1, 0)\n",
    "\n",
    "\n",
    "        #Evaluating fitness of new solution\n",
    "        try:\n",
    "            new_fitness = runModel(t, i, new_solution)\n",
    "        #except tf.errors.ResourceExhaustedError as e:\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            new_fitness = 0            \n",
    "\n",
    "        if new_fitness > fitness_[i]:      #Greedy selection\n",
    "            population_[i] = new_solution\n",
    "            fitness_[i] = new_fitness\n",
    "\n",
    "    bestidx_ = np.argmax(fitness_)  # update details\n",
    "    print(\"After \", t, \" iteration: \", population_[bestidx_], fitness_[bestidx_]) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
